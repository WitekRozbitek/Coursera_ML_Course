{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"./amazon_baby.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Text cleaning \n",
    "remove punctation + lowercases\n",
    "\n",
    "maketrans = the method returns a translation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "translator = str.maketrans('','', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before calling f-n we need to change type to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products[\"review\"] = products[\"review\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_string(x):\n",
    "    x = x.translate(translator)\n",
    "    x = x.lower()\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products[\"cleaned review\"] = products[\"review\"].apply(normalize_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products[products[\"rating\"] != 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products[\"sentiment\"] = products[\"rating\"].apply(lambda rating: 1 if rating > 3 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Reading from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('./module-2-assignment-test-idx.json') as data_file:    \n",
    "    test_pos = json.load(data_file)\n",
    "    \n",
    "with open('./module-2-assignment-train-idx.json') as data_file:    \n",
    "    train_pos = json.load(data_file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = products.iloc[test_pos]\n",
    "train = products.iloc[train_pos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Build the word count vector for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counter(x):\n",
    "    x = x.split()\n",
    "    return Counter(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name              object\n",
       "review            object\n",
       "rating             int64\n",
       "cleaned review    object\n",
       "sentiment          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_matrix = vectorizer.fit_transform(train['cleaned review'])\n",
    "test_matrix = vectorizer.transform(test['cleaned review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<133416x121713 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7327230 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_model = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.fit(train_matrix, train[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.24034744e+00,   2.79931254e-05,   2.69580456e-02, ...,\n",
       "          1.28787106e-02,   2.62606208e-03,  -4.03239461e-05]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.32997203])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([87053])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sentiment_model.coef_ >= 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34660])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sentiment_model.coef_ < 0, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_test_data = test[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.iloc[0][\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would not purchase again or recommend. The decals were thick almost plastic like and were coming off the wall as I was applying them! The would NOT stick! Literally stayed stuck for about 5 minutes then started peeling off.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.iloc[1][\"review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_test_matrix = vectorizer.transform(sample_test_data['cleaned review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = sentiment_model.decision_function(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.58696596,  -3.18405772, -10.4295896 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_score(data, co):\n",
    "    scores = sentiment_model.decision_function(data)\n",
    "    return ( scores >= 0 ) *2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_score(sample_test_matrix,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_from_score(scores):\n",
    "    return 1/ (1 + np.exp(-1 * scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.96267606e-01,   3.97700864e-02,   2.95443171e-05])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_from_score(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3rd had the lowest prob to be positive\n",
    "\n",
    "13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scores = sentiment_model.decision_function(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_train_scores = pd.DataFrame(prob_from_score(train_scores), columns =[\"probability\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train, prob_train_scores], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.index = train[\"index\"]\n",
    "del train[\"index\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take top 20 probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = train.sort_values(\"probability\", ascending = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleaned review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47813</th>\n",
       "      <td>Baby K'tan Baby Carrier, Black, X-Large</td>\n",
       "      <td>Check and recheck the K'Tan for size issues be...</td>\n",
       "      <td>5</td>\n",
       "      <td>check and recheck the ktan for size issues bef...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88659</th>\n",
       "      <td>ERGObaby Original Baby Carrier, Galaxy Grey</td>\n",
       "      <td>We purchased this carrier after a recommendati...</td>\n",
       "      <td>5</td>\n",
       "      <td>we purchased this carrier after a recommendati...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123632</th>\n",
       "      <td>Zooper 2011 Waltz Standard Stroller, Flax Brown</td>\n",
       "      <td>I did a TON of research before I purchased thi...</td>\n",
       "      <td>5</td>\n",
       "      <td>i did a ton of research before i purchased thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28530</th>\n",
       "      <td>HALO SleepSack Big Kids Micro-Fleece Wearable ...</td>\n",
       "      <td>OVERVIEW: My daughter has to be one of the wil...</td>\n",
       "      <td>4</td>\n",
       "      <td>overview my daughter has to be one of the wild...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88680</th>\n",
       "      <td>ERGObaby Original Baby Carrier, Galaxy Grey</td>\n",
       "      <td>After reading many online reviews, asking othe...</td>\n",
       "      <td>5</td>\n",
       "      <td>after reading many online reviews asking other...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "index                                                       \n",
       "47813             Baby K'tan Baby Carrier, Black, X-Large   \n",
       "88659         ERGObaby Original Baby Carrier, Galaxy Grey   \n",
       "123632    Zooper 2011 Waltz Standard Stroller, Flax Brown   \n",
       "28530   HALO SleepSack Big Kids Micro-Fleece Wearable ...   \n",
       "88680         ERGObaby Original Baby Carrier, Galaxy Grey   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "index                                                               \n",
       "47813   Check and recheck the K'Tan for size issues be...       5   \n",
       "88659   We purchased this carrier after a recommendati...       5   \n",
       "123632  I did a TON of research before I purchased thi...       5   \n",
       "28530   OVERVIEW: My daughter has to be one of the wil...       4   \n",
       "88680   After reading many online reviews, asking othe...       5   \n",
       "\n",
       "                                           cleaned review  sentiment  \\\n",
       "index                                                                  \n",
       "47813   check and recheck the ktan for size issues bef...          1   \n",
       "88659   we purchased this carrier after a recommendati...          1   \n",
       "123632  i did a ton of research before i purchased thi...          1   \n",
       "28530   overview my daughter has to be one of the wild...          1   \n",
       "88680   after reading many online reviews asking other...          1   \n",
       "\n",
       "        probability  \n",
       "index                \n",
       "47813           1.0  \n",
       "88659           1.0  \n",
       "123632          1.0  \n",
       "28530           1.0  \n",
       "88680           1.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_accuracy(data):\n",
    "\n",
    "    predicted_class = sentiment_model.predict(data)\n",
    "    predicted_class = pd.DataFrame(predicted_class, columns = [\"predicted class\"])\n",
    "\n",
    "    train_tmp = train[\"sentiment\"]\n",
    "    train_tmp = train_tmp.reset_index()\n",
    "    train_tmp = pd.concat([train_tmp, predicted_class], axis = 1)\n",
    "    \n",
    "    train_tmp[\"correct\"] = (train_tmp[\"sentiment\"] == train_tmp[\"predicted class\"]) * 1\n",
    "    return round(sum(train[\"correct\"]) / len(train[\"correct\"]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_accuracy(train_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves','well', 'able', 'car', \n",
    "                     'broke', 'less', 'even', 'waste', 'disappointed','work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_word_subset = CountVectorizer(vocabulary = significant_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train['cleaned review'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test['cleaned review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model = linear_model.LogisticRegression()\n",
    "simple_model.fit(train_matrix_word_subset, train[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten covert list of list to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_model_weights = pd.DataFrame({\"words\": significant_words, \n",
    "                                     \"coefs\": simple_model.coef_.flatten().tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_model_weights = simple_model_weights.sort_values([\"coefs\"], ascending = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.673074</td>\n",
       "      <td>loves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.509812</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.363690</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192538</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.944000</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.520186</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.503760</td>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.190909</td>\n",
       "      <td>able</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085513</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.058855</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.209563</td>\n",
       "      <td>less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.320556</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.362167</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.511380</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.621169</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.898031</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.651576</td>\n",
       "      <td>broke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-2.033699</td>\n",
       "      <td>waste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-2.109331</td>\n",
       "      <td>return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-2.348298</td>\n",
       "      <td>disappointed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coefs         words\n",
       "6   1.673074         loves\n",
       "5   1.509812       perfect\n",
       "0   1.363690          love\n",
       "2   1.192538          easy\n",
       "1   0.944000         great\n",
       "4   0.520186        little\n",
       "7   0.503760          well\n",
       "8   0.190909          able\n",
       "3   0.085513           old\n",
       "9   0.058855           car\n",
       "11 -0.209563          less\n",
       "16 -0.320556       product\n",
       "18 -0.362167         would\n",
       "12 -0.511380          even\n",
       "15 -0.621169          work\n",
       "17 -0.898031         money\n",
       "10 -1.651576         broke\n",
       "13 -2.033699         waste\n",
       "19 -2.109331        return\n",
       "14 -2.348298  disappointed"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((simple_model_weights[\"coefs\"] > 0) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()\n",
    "coefs = sentiment_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model_weights = pd.DataFrame({\"words\": features, \n",
    "                                     \"coefs\": coefs.flatten().tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_models = pd.merge(sentiment_model_weights, simple_model_weights,\n",
    "                     how = \"inner\", on = \"words\",\n",
    "                     suffixes=('_sent', '_simp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs_sent</th>\n",
       "      <th>words</th>\n",
       "      <th>coefs_simp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.389155</td>\n",
       "      <td>broke</td>\n",
       "      <td>-1.651576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.191512</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>-2.348298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.465401</td>\n",
       "      <td>even</td>\n",
       "      <td>-0.511380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.275714</td>\n",
       "      <td>less</td>\n",
       "      <td>-0.209563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.784390</td>\n",
       "      <td>money</td>\n",
       "      <td>-0.898031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.187108</td>\n",
       "      <td>product</td>\n",
       "      <td>-0.320556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.657048</td>\n",
       "      <td>return</td>\n",
       "      <td>-2.109331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.991709</td>\n",
       "      <td>waste</td>\n",
       "      <td>-2.033699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.459104</td>\n",
       "      <td>work</td>\n",
       "      <td>-0.621169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.287350</td>\n",
       "      <td>would</td>\n",
       "      <td>-0.362167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    coefs_sent         words  coefs_simp\n",
       "1    -1.389155         broke   -1.651576\n",
       "3    -2.191512  disappointed   -2.348298\n",
       "5    -0.465401          even   -0.511380\n",
       "7    -0.275714          less   -0.209563\n",
       "11   -0.784390         money   -0.898031\n",
       "14   -0.187108       product   -0.320556\n",
       "15   -1.657048        return   -2.109331\n",
       "16   -1.991709         waste   -2.033699\n",
       "18   -0.459104          work   -0.621169\n",
       "19   -0.287350         would   -0.362167"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_models[two_models[\"coefs_simp\"] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_accuracry(data):\n",
    "    predicted_class = simple_model.predict(data)\n",
    "    predicted_class = pd.DataFrame(predicted_class, columns = [\"predicted class - simple\"])\n",
    "\n",
    "    train_tmp = train[\"sentiment\"]\n",
    "    train_tmp = train_tmp.reset_index()\n",
    "    \n",
    "    train_tmp = pd.concat([train_tmp, predicted_class], axis = 1)\n",
    "    train_tmp.index = train_tmp[\"index\"]\n",
    "    \n",
    "    train_tmp[\"correct - simple\"] = (train_tmp[\"sentiment\"] == train_tmp[\"predicted class - simple\"]) * 1\n",
    "    \n",
    "    return round(sum(train_tmp[\"correct - simple\"]) / len(train_tmp[\"correct - simple\"]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87 0.97\n"
     ]
    }
   ],
   "source": [
    "print(simple_accuracry(train_matrix_word_subset), sentiment_accuracy(train_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.97\n"
     ]
    }
   ],
   "source": [
    "print(simple_accuracry(test_matrix_word_subset), sentiment_accuracy(test_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  21252.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,  112164.]),\n",
       " array([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nm6EhSepmaEiSuhkakqRuhoYkqdv/B26k/jnALlDUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c766278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the major group is positive review.\n",
    "\n",
    "Accuracy for that predictor is (respectively train, test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84070876056844757"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum( (train[\"sentiment\"] == 1) * 1 ) / len(train[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84278257739380846"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum( (test[\"sentiment\"] == 1) * 1 ) / len(test[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the sentiment full modeal beats the majority model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
