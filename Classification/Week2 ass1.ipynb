{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import math\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"./amazon_baby_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  All of my kids have cried non-stop when I trie...       5          1  \n",
       "1  We wanted to get something to keep track of ou...       5          1  \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1  \n",
       "3  One of baby's first and favorite books, and it...       4          1  \n",
       "4  Very cute interactive book! My son loves this ...       5          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26579"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum( (products[\"sentiment\"] == 1) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26493"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum( (products[\"sentiment\"] != 1) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./important_words.json') as data_file:    \n",
    "    important_words = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna({\"review\": \"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "translator = str.maketrans('','', string.punctuation)\n",
    "products[\"review\"] = products[\"review\"].astype(str)\n",
    "\n",
    "def normalize_string(x):\n",
    "    x = x.str.translate(translator)\n",
    "    x = x.str.lower()\n",
    "    \n",
    "    return x\n",
    "\n",
    "def normalize_string_old(x):\n",
    "    x = x.translate(translator)\n",
    "    x = x.lower()\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 312 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "products[\"review_clean\"] = normalize_string(products[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 281 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "products[\"review_clean\"] = products[\"review\"].apply(normalize_string_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1min 34s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for word in important_words:\n",
    "    products[word] = products[\"review_clean\"].apply(lambda x: x.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit <- this produces NAN, why?\n",
    "products[\"list\"] = products[\"review_clean\"].str.split()\n",
    "\n",
    "for word in important_words:\n",
    "    products[word] = products[\"list\"].str.count(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 3.98 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "vectorizer_word_subset = CountVectorizer(vocabulary = important_words)\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(products['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3309"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum( 1* products[\"perfect\"] > 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, label):\n",
    "    \n",
    "    dataframe[\"constant\"] = 1\n",
    "    features = [\"constant\"] + features\n",
    "    \n",
    "    feature_matrix = dataframe[features].as_matrix()\n",
    "    label_array = dataframe[label].as_matrix()\n",
    "    return (feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix, label_array = get_numpy_data(products, important_words, \"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53072, 194)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_probability(feature_matrix, coefficients):\n",
    "    score = np.dot(feature_matrix,coefficients)\n",
    "    \n",
    "    predictions = 1/(1 + np.exp(-score))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    return np.dot(errors, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    \n",
    "    indicator = (sentiment == 1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    \n",
    "    lp = np.sum((indicator - 1) * scores - np.log(1 + np.exp(-scores)))\n",
    "    \n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(feature_matrix, sentiment, initial_coeffs, \n",
    "                        step_size, max_iter) :\n",
    "    \n",
    "    coeffs = np.array(initial_coeffs)\n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iter:\n",
    "        \n",
    "        predictions = predict_probability(feature_matrix, coeffs)\n",
    "        indicator = 1* (sentiment == 1)\n",
    "        errors = indicator - predictions\n",
    "        \n",
    "        for i in range(len(coeffs)):\n",
    "            \n",
    "            derivative = feature_derivative(errors, feature_matrix[:,i])\n",
    "            \n",
    "            coeffs[i] += step_size * derivative\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        if iteration <= 15 or (iteration <= 100 and iteration % 10 == 0) or (iteration <= 1000 and iteration % 100 == 0) \\\n",
    "        or (iteration <= 10000 and iteration % 1000 == 0) or iteration % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coeffs)\n",
    "            print ('iteration %*d: log likelihood of observed labels = %.8f' % (int(np.ceil(np.log10(max_iter))), iteration, lp))\n",
    "        \n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fm = feature_matrix\n",
    "st = label_array\n",
    "initial_coeffs = np.array([0.0] * feature_matrix.shape[1])\n",
    "step_size = 1e-7\n",
    "max_iter = 301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   1: log likelihood of observed labels = -36779.70627863\n",
      "iteration   2: log likelihood of observed labels = -36772.71312191\n",
      "iteration   3: log likelihood of observed labels = -36765.72767668\n",
      "iteration   4: log likelihood of observed labels = -36758.74992322\n",
      "iteration   5: log likelihood of observed labels = -36751.77984195\n",
      "iteration   6: log likelihood of observed labels = -36744.81741345\n",
      "iteration   7: log likelihood of observed labels = -36737.86261842\n",
      "iteration   8: log likelihood of observed labels = -36730.91543769\n",
      "iteration   9: log likelihood of observed labels = -36723.97585224\n",
      "iteration  10: log likelihood of observed labels = -36717.04384317\n",
      "iteration  11: log likelihood of observed labels = -36710.11939171\n",
      "iteration  12: log likelihood of observed labels = -36703.20247923\n",
      "iteration  13: log likelihood of observed labels = -36696.29308721\n",
      "iteration  14: log likelihood of observed labels = -36689.39119727\n",
      "iteration  15: log likelihood of observed labels = -36682.49679115\n",
      "iteration  20: log likelihood of observed labels = -36648.13638740\n",
      "iteration  30: log likelihood of observed labels = -36579.96670810\n",
      "iteration  40: log likelihood of observed labels = -36512.51787117\n",
      "iteration  50: log likelihood of observed labels = -36445.77397975\n",
      "iteration  60: log likelihood of observed labels = -36379.72006835\n",
      "iteration  70: log likelihood of observed labels = -36314.34200963\n",
      "iteration  80: log likelihood of observed labels = -36249.62643213\n",
      "iteration  90: log likelihood of observed labels = -36185.56064764\n",
      "iteration 100: log likelihood of observed labels = -36122.13258712\n",
      "iteration 200: log likelihood of observed labels = -35520.61731277\n",
      "iteration 300: log likelihood of observed labels = -34972.62003353\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression(fm, st, initial_coeffs, step_size, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_score = np.dot(feature_matrix, coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_class = 2* (final_score >= 0) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25237 27835\n"
     ]
    }
   ],
   "source": [
    "print(sum( 1 * final_class == 1 ), sum( 1 * final_class != 1 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = sum(1*(final_class == label_array)) / len(final_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "print(round(acc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficients = list(coefficients[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_coeffs_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_coeffs_tuples = sorted(word_coeffs_tuples, key = lambda x:x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 0.084119424383667249),\n",
       " ('great', 0.08311194239481122),\n",
       " ('easy', 0.073503830170933745),\n",
       " ('loves', 0.048081701602836098),\n",
       " ('little', 0.045369103717335692),\n",
       " ('perfect', 0.034437993486444413),\n",
       " ('well', 0.02765945177922657),\n",
       " ('nice', 0.020781358649221086),\n",
       " ('old', 0.019747740577050456),\n",
       " ('fits', 0.019133111494995469)]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coeffs_tuples[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('return', -0.02680721350222864),\n",
       " ('waste', -0.027196962011447265),\n",
       " ('back', -0.028219842211087653),\n",
       " ('get', -0.029491013575623962),\n",
       " ('disappointed', -0.030485382478378471),\n",
       " ('even', -0.033105049970913902),\n",
       " ('work', -0.033181734209090492),\n",
       " ('money', -0.04028587082625365),\n",
       " ('product', -0.042707473571271297),\n",
       " ('would', -0.05259056720690225)]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coeffs_tuples[-10:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
